<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<parent>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-boot-starter-parent</artifactId>
		<version>4.0.1</version>
		<relativePath/> <!-- lookup parent from repository -->
	</parent>
	<groupId>com.mukesh.coldstorageexp</groupId>
	<artifactId>parquetreadwrite</artifactId>
	<version>0.0.1-SNAPSHOT</version>
	<name>parquetreadwrite</name>
	<description>Demo project for Spring Boot</description>
	<url/>
	<licenses>
		<license/>
	</licenses>
	<developers>
		<developer/>
	</developers>
	<scm>
		<connection/>
		<developerConnection/>
		<tag/>
		<url/>
	</scm>
	<properties>
		<java.version>17</java.version>
		<iceberg.version>1.4.2</iceberg.version>
	</properties>
	<dependencies>
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter</artifactId>
		</dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>

		<!-- AWS SDK v2 for S3 remote writer -->
		<dependency>
			<groupId>software.amazon.awssdk</groupId>
			<artifactId>s3</artifactId>
			<version>2.20.118</version>
		</dependency>

		<!-- Parquet / Avro for reading/writing parquet files -->
		<dependency>
			<groupId>org.apache.parquet</groupId>
			<artifactId>parquet-avro</artifactId>
			<version>1.12.3</version>
		</dependency>

		<dependency>
			<groupId>org.apache.avro</groupId>
			<artifactId>avro</artifactId>
			<version>1.11.1</version>
		</dependency>

		<!-- Hadoop common is used for Path/Configuration used by parquet writer/reader -->
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-common</artifactId>
			<version>3.3.4</version>
		</dependency>

		<!-- Hadoop S3A for S3 access -->
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-aws</artifactId>
			<version>3.3.4</version>
		</dependency>

		<!-- MapReduce client core provides FileOutputFormat required by parquet-hadoop builder -->
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-mapreduce-client-core</artifactId>
			<version>3.3.4</version>
		</dependency>

		<!-- Apache Iceberg -->
		<dependency>
			<groupId>org.apache.iceberg</groupId>
			<artifactId>iceberg-core</artifactId>
			<version>${iceberg.version}</version>
		</dependency>

		<dependency>
			<groupId>org.apache.iceberg</groupId>
			<artifactId>iceberg-api</artifactId>
			<version>${iceberg.version}</version>
		</dependency>

		<dependency>
			<groupId>org.apache.iceberg</groupId>
			<artifactId>iceberg-parquet</artifactId>
			<version>${iceberg.version}</version>
		</dependency>

		<!-- Iceberg AWS support (S3, Glue) -->
		<dependency>
			<groupId>org.apache.iceberg</groupId>
			<artifactId>iceberg-aws</artifactId>
			<version>${iceberg.version}</version>
		</dependency>

		<!-- Iceberg JDBC Catalog for PostgreSQL -->
		<dependency>
			<groupId>org.postgresql</groupId>
			<artifactId>postgresql</artifactId>
			<version>42.7.1</version>
		</dependency>

		<!-- DuckDB JDBC for querying Iceberg tables from S3 -->
		<dependency>
			<groupId>org.duckdb</groupId>
			<artifactId>duckdb_jdbc</artifactId>
			<version>1.2.1</version>
		</dependency>

		<!-- Spring Boot Actuator for health checks -->
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-actuator</artifactId>
		</dependency>

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-test</artifactId>
			<scope>test</scope>
		</dependency>
	</dependencies>

	<build>
		<plugins>
			<plugin>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-maven-plugin</artifactId>
			</plugin>
		</plugins>
	</build>

</project>
